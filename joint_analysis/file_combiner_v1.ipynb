{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a712ed5-14ee-4f5c-b967-5ae371ad5e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14.4\n"
     ]
    }
   ],
   "source": [
    "#import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uproot3 as uproot\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(uproot.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1cc93e-b640-4a0f-8459-6869d6c4cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glee_file_location = \"/data1/hagaman/glee_files/SBNfit_files/\"\n",
    "wc_file_location = \"/data1/hagaman/xin_files/processed_checkout_rootfiles/\" # training events removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb1b1b6-9e24-4b8d-a8f2-1ca2827a6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the variables we want to extract from the glee files\n",
    "glee_vars = [\n",
    "    \"run_number\",\n",
    "    \"subrun_number\",\n",
    "    \"event_number\",\n",
    "    \"reco_shower_energy_plane0\",\n",
    "    \"reco_shower_energy_plane1\",\n",
    "    \"reco_shower_energy_plane2\",\n",
    "    \"reco_shower_energy_max\",\n",
    "    \"reco_vertex_x\",\n",
    "    \"reco_vertex_y\",\n",
    "    \"reco_vertex_z\",\n",
    "]\n",
    "\n",
    "# the variables we want to extract from the WC files\n",
    "wc_vars = [\n",
    "    \"data_or_pred\",\n",
    "    \"run\",\n",
    "    \"subrun\",\n",
    "    \"event\",\n",
    "    \"category\",\n",
    "    \"WC_file\",\n",
    "    \"match_isFC\",\n",
    "    \"kine_reco_Enu\",\n",
    "    \"reco_showerKE\",\n",
    "    \"nc_delta_score\",\n",
    "    \"WC_reco_num_protons\",\n",
    "    \"WC_reco_num_other_tracks\",\n",
    "    \"reco_nuvtxX\",\n",
    "    \"reco_nuvtxY\",\n",
    "    \"reco_nuvtxZ\",\n",
    "    \"truth_vtxX\",\n",
    "    \"truth_vtxY\",\n",
    "    \"truth_vtxZ\",\n",
    "    \"net_weight\",\n",
    "]\n",
    "\n",
    "# the variables we want to extract from the WC files\n",
    "wc_data_vars = [\n",
    "    \"data_or_pred\",\n",
    "    \"run\",\n",
    "    \"subrun\",\n",
    "    \"event\",\n",
    "    \"WC_file\",\n",
    "    \"match_isFC\",\n",
    "    \"kine_reco_Enu\",\n",
    "    \"reco_showerKE\",\n",
    "    \"nc_delta_score\",\n",
    "    \"WC_reco_num_protons\",\n",
    "    \"WC_reco_num_other_tracks\",\n",
    "    \"reco_nuvtxX\",\n",
    "    \"reco_nuvtxY\",\n",
    "    \"reco_nuvtxZ\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f806a0c-5b15-4b04-9c31-69e569d0e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading glee root files\n",
    "\n",
    "glee_1g0p_location = glee_file_location + \"1g0p/\"\n",
    "f_glee_1g0p_NCDeltaRadOverlaySM = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_NCDeltaRadOverlaySM.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_NCPi0Coh = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_NCPi0Coh.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_NCPi0NotCoh = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_NCPi0NotCoh.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_CC1Pi0 = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_CC1Pi0.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_NueOverlays = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_NueOverlays.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_OTPCExtra = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_OTPCExtra.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_BNBOtherExtra = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_BNBOtherExtra.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_Dirt = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_Dirt.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_BNBext = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_stage_4_BNBext.root\")[\"singlephoton\"]\n",
    "f_glee_1g0p_data = uproot.open(glee_1g0p_location + \"sbnfit_1g0pMar2020_RealRedoLiveUnblinding_stage_4_FinalSelection1g0p.root\")[\"singlephoton\"]\n",
    "\n",
    "glee_1g1p_location = glee_file_location + \"1g1p/\"\n",
    "f_glee_1g1p_NCDeltaRadOverlaySM = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_NCDeltaRadOverlaySM.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_NCPi0Coh = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_NCPi0Coh.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_NCPi0NotCoh = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_NCPi0NotCoh.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_CC1Pi0 = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_CC1Pi0.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_NueOverlays = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_NueOverlays.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_OTPCExtra = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_OTPCExtra.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_BNBOtherExtra = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_BNBOtherExtra.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_Dirt = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_Dirt.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_BNBext = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_stage_6_BNBext.root\")[\"singlephoton\"]\n",
    "f_glee_1g1p_data = uproot.open(glee_1g1p_location + \"sbnfit_1g1pMar2020_v4_RealRedoLiveUnblinding_stage_6_FinalSelection1g1p.root\")[\"singlephoton\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe49520e-0b6c-403a-b34a-88729f94859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting information from the glee root files into pandas dataframes\n",
    "\n",
    "\n",
    "# 1g0p pred files\n",
    "\n",
    "glee_1g0p_NCDeltaRadOverlaySM_df = pd.concat([\n",
    "    f_glee_1g0p_NCDeltaRadOverlaySM[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_NCDeltaRadOverlaySM[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_NCDeltaRadOverlaySM\n",
    "glee_1g0p_NCDeltaRadOverlaySM_df[\"glee_file\"] = \"NCDeltaRadOverlaySM\"\n",
    "glee_1g0p_NCDeltaRadOverlaySM_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_NCPi0Coh_df = pd.concat([\n",
    "    f_glee_1g0p_NCPi0Coh[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_NCPi0Coh[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_NCPi0Coh\n",
    "glee_1g0p_NCPi0Coh_df[\"glee_file\"] = \"NCPi0Coh\"\n",
    "glee_1g0p_NCPi0Coh_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_NCPi0NotCoh_df = pd.concat([\n",
    "    f_glee_1g0p_NCPi0NotCoh[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_NCPi0NotCoh[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_NCPi0NotCoh\n",
    "glee_1g0p_NCPi0NotCoh_df[\"glee_file\"] = \"NCPi0NotCoh\"\n",
    "glee_1g0p_NCPi0NotCoh_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_CC1Pi0_df = pd.concat([\n",
    "    f_glee_1g0p_CC1Pi0[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_CC1Pi0[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_CC1Pi0\n",
    "glee_1g0p_CC1Pi0_df[\"glee_file\"] = \"CC1Pi0\"\n",
    "glee_1g0p_CC1Pi0_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_NueOverlays_df = pd.concat([\n",
    "    f_glee_1g0p_NueOverlays[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_NueOverlays[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_NueOverlays\n",
    "glee_1g0p_NueOverlays_df[\"glee_file\"] = \"NueOverlays\"\n",
    "glee_1g0p_NueOverlays_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_OTPCExtra_df = pd.concat([\n",
    "    f_glee_1g0p_OTPCExtra[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_OTPCExtra[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_OTPCExtra\n",
    "glee_1g0p_OTPCExtra_df[\"glee_file\"] = \"OTPCExtra\"\n",
    "glee_1g0p_OTPCExtra_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_BNBOtherExtra_df = pd.concat([\n",
    "    f_glee_1g0p_BNBOtherExtra[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_BNBOtherExtra[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_BNBOtherExtra\n",
    "glee_1g0p_BNBOtherExtra_df[\"glee_file\"] = \"BNBOtherExtra\"\n",
    "glee_1g0p_BNBOtherExtra_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_Dirt_df = pd.concat([\n",
    "    f_glee_1g0p_Dirt[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_Dirt[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_Dirt\n",
    "glee_1g0p_Dirt_df[\"glee_file\"] = \"Dirt\"\n",
    "glee_1g0p_Dirt_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g0p_BNBext_df = pd.concat([\n",
    "    f_glee_1g0p_BNBext[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_BNBext[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_BNBext\n",
    "glee_1g0p_BNBext_df[\"glee_file\"] = \"BNBext\"\n",
    "glee_1g0p_BNBext_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "\n",
    "# 1g1p pred files\n",
    "\n",
    "glee_1g1p_NCDeltaRadOverlaySM_df = pd.concat([\n",
    "    f_glee_1g1p_NCDeltaRadOverlaySM[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_NCDeltaRadOverlaySM[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_NCDeltaRadOverlaySM\n",
    "glee_1g1p_NCDeltaRadOverlaySM_df[\"glee_file\"] = \"NCDeltaRadOverlaySM\"\n",
    "glee_1g1p_NCDeltaRadOverlaySM_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_NCPi0Coh_df = pd.concat([\n",
    "    f_glee_1g1p_NCPi0Coh[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_NCPi0Coh[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_NCPi0Coh\n",
    "glee_1g1p_NCPi0Coh_df[\"glee_file\"] = \"NCPi0Coh\"\n",
    "glee_1g1p_NCPi0Coh_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_NCPi0NotCoh_df = pd.concat([\n",
    "    f_glee_1g1p_NCPi0NotCoh[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_NCPi0NotCoh[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_NCPi0NotCoh\n",
    "glee_1g1p_NCPi0NotCoh_df[\"glee_file\"] = \"NCPi0NotCoh\"\n",
    "glee_1g1p_NCPi0NotCoh_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_CC1Pi0_df = pd.concat([\n",
    "    f_glee_1g1p_CC1Pi0[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_CC1Pi0[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_CC1Pi0\n",
    "glee_1g1p_CC1Pi0_df[\"glee_file\"] = \"CC1Pi0\"\n",
    "glee_1g1p_CC1Pi0_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_NueOverlays_df = pd.concat([\n",
    "    f_glee_1g1p_NueOverlays[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_NueOverlays[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_NueOverlays\n",
    "glee_1g1p_NueOverlays_df[\"glee_file\"] = \"NueOverlays\"\n",
    "glee_1g1p_NueOverlays_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_OTPCExtra_df = pd.concat([\n",
    "    f_glee_1g1p_OTPCExtra[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_OTPCExtra[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_OTPCExtra\n",
    "glee_1g1p_OTPCExtra_df[\"glee_file\"] = \"OTPCExtra\"\n",
    "glee_1g1p_OTPCExtra_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_BNBOtherExtra_df = pd.concat([\n",
    "    f_glee_1g1p_BNBOtherExtra[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_BNBOtherExtra[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_BNBOtherExtra\n",
    "glee_1g1p_BNBOtherExtra_df[\"glee_file\"] = \"BNBOtherExtra\"\n",
    "glee_1g1p_BNBOtherExtra_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_Dirt_df = pd.concat([\n",
    "    f_glee_1g1p_Dirt[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_Dirt[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_Dirt\n",
    "glee_1g1p_Dirt_df[\"glee_file\"] = \"Dirt\"\n",
    "glee_1g1p_Dirt_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "glee_1g1p_BNBext_df = pd.concat([\n",
    "    f_glee_1g1p_BNBext[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_BNBext[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_BNBext\n",
    "glee_1g1p_BNBext_df[\"glee_file\"] = \"BNBext\"\n",
    "glee_1g1p_BNBext_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data files\n",
    "\n",
    "glee_1g0p_data_df = pd.concat([\n",
    "    f_glee_1g0p_data[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g0p_data[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g0p_data\n",
    "glee_1g0p_data_df[\"glee_file\"] = \"data\"\n",
    "glee_1g0p_data_df[\"glee_selection\"] = \"1g0p\"\n",
    "\n",
    "glee_1g1p_data_df = pd.concat([\n",
    "    f_glee_1g1p_data[\"vertex_tree\"].pandas.df(glee_vars, flatten=False),\n",
    "    f_glee_1g1p_data[\"simple_tree\"].pandas.df([\"simple_pot_weight\"], flatten=False),\n",
    "    ], axis=1, sort=False)\n",
    "del f_glee_1g1p_data\n",
    "glee_1g1p_data_df[\"glee_file\"] = \"data\"\n",
    "glee_1g1p_data_df[\"glee_selection\"] = \"1g1p\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c5e0ae-3cc6-4f3e-ac3a-60d87a8bf5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glee_pred_df = pd.concat([\n",
    "    glee_1g0p_NCDeltaRadOverlaySM_df,\n",
    "    glee_1g0p_NCPi0Coh_df,\n",
    "    glee_1g0p_NCPi0NotCoh_df,\n",
    "    glee_1g0p_CC1Pi0_df,\n",
    "    glee_1g0p_NueOverlays_df,\n",
    "    glee_1g0p_OTPCExtra_df,\n",
    "    glee_1g0p_BNBOtherExtra_df,\n",
    "    glee_1g0p_Dirt_df,\n",
    "    glee_1g0p_BNBext_df,\n",
    "    glee_1g1p_NCDeltaRadOverlaySM_df,\n",
    "    glee_1g1p_NCPi0Coh_df,\n",
    "    glee_1g1p_NCPi0NotCoh_df,\n",
    "    glee_1g1p_CC1Pi0_df,\n",
    "    glee_1g1p_NueOverlays_df,\n",
    "    glee_1g1p_OTPCExtra_df,\n",
    "    glee_1g1p_BNBOtherExtra_df,\n",
    "    glee_1g1p_Dirt_df,\n",
    "    glee_1g1p_BNBext_df,\n",
    "    ], sort=False)\n",
    "glee_pred_df[\"data_or_pred\"] = [\"pred\" for i in range(glee_pred_df.shape[0])]\n",
    "\n",
    "glee_data_df = pd.concat([\n",
    "    glee_1g0p_data_df,\n",
    "    glee_1g1p_data_df,\n",
    "    ], sort=False)\n",
    "glee_data_df[\"data_or_pred\"] = [\"data\" for i in range(glee_data_df.shape[0])]\n",
    "\n",
    "glee_all_df = pd.concat([\n",
    "        glee_pred_df,\n",
    "        glee_data_df,\n",
    "    ], sort=False)\n",
    "glee_all_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ddd146-a439-4979-86df-0661e562d9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 5716/5716 [00:00<00:00, 1395578.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# changing one element lists to floats\n",
    "\n",
    "reco_shower_energy_plane0_arr = []\n",
    "reco_shower_energy_plane1_arr = []\n",
    "reco_shower_energy_plane2_arr = []\n",
    "reco_shower_energy_max_arr = []\n",
    "reco_shower_energy_plane0_lists = glee_all_df[\"reco_shower_energy_plane0\"].to_numpy()\n",
    "reco_shower_energy_plane1_lists = glee_all_df[\"reco_shower_energy_plane1\"].to_numpy()\n",
    "reco_shower_energy_plane2_lists = glee_all_df[\"reco_shower_energy_plane2\"].to_numpy()\n",
    "reco_shower_energy_max_lists = glee_all_df[\"reco_shower_energy_max\"].to_numpy()\n",
    "\n",
    "for i in tqdm(range(glee_all_df.shape[0])):    \n",
    "    reco_shower_energy_plane0_arr.append(reco_shower_energy_plane0_lists[i][0])\n",
    "    reco_shower_energy_plane1_arr.append(reco_shower_energy_plane1_lists[i][0])\n",
    "    reco_shower_energy_plane2_arr.append(reco_shower_energy_plane2_lists[i][0])\n",
    "    reco_shower_energy_max_arr.append(reco_shower_energy_max_lists[i][0])\n",
    "\n",
    "glee_all_df[\"reco_shower_energy_plane0\"] = reco_shower_energy_plane0_arr\n",
    "glee_all_df[\"reco_shower_energy_plane1\"] = reco_shower_energy_plane1_arr\n",
    "glee_all_df[\"reco_shower_energy_plane2\"] = reco_shower_energy_plane2_arr\n",
    "glee_all_df[\"reco_shower_energy_max\"] = reco_shower_energy_max_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ecc016-551a-45d3-8959-744048015cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "glee_all_df = glee_all_df.rename(columns={\"run_number\": \"run\", \"subrun_number\": \"subrun\", \"event_number\":\"event\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c69ed39-3753-4830-a1e1-b3b889be9214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry</th>\n",
       "      <th>run</th>\n",
       "      <th>subrun</th>\n",
       "      <th>event</th>\n",
       "      <th>reco_shower_energy_plane0</th>\n",
       "      <th>reco_shower_energy_plane1</th>\n",
       "      <th>reco_shower_energy_plane2</th>\n",
       "      <th>reco_shower_energy_max</th>\n",
       "      <th>reco_vertex_x</th>\n",
       "      <th>reco_vertex_y</th>\n",
       "      <th>reco_vertex_z</th>\n",
       "      <th>simple_pot_weight</th>\n",
       "      <th>glee_file</th>\n",
       "      <th>glee_selection</th>\n",
       "      <th>data_or_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6058</td>\n",
       "      <td>81</td>\n",
       "      <td>4079</td>\n",
       "      <td>288.261817</td>\n",
       "      <td>310.056054</td>\n",
       "      <td>309.773263</td>\n",
       "      <td>310.056054</td>\n",
       "      <td>167.029160</td>\n",
       "      <td>-61.018150</td>\n",
       "      <td>387.096191</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>NCDeltaRadOverlaySM</td>\n",
       "      <td>1g0p</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6058</td>\n",
       "      <td>81</td>\n",
       "      <td>4100</td>\n",
       "      <td>118.919947</td>\n",
       "      <td>189.828308</td>\n",
       "      <td>220.959059</td>\n",
       "      <td>220.959059</td>\n",
       "      <td>103.585838</td>\n",
       "      <td>-76.903328</td>\n",
       "      <td>578.505981</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>NCDeltaRadOverlaySM</td>\n",
       "      <td>1g0p</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6221</td>\n",
       "      <td>10</td>\n",
       "      <td>537</td>\n",
       "      <td>255.901477</td>\n",
       "      <td>291.085256</td>\n",
       "      <td>320.449278</td>\n",
       "      <td>320.449278</td>\n",
       "      <td>110.947716</td>\n",
       "      <td>28.835058</td>\n",
       "      <td>965.170654</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>NCDeltaRadOverlaySM</td>\n",
       "      <td>1g0p</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6827</td>\n",
       "      <td>72</td>\n",
       "      <td>3605</td>\n",
       "      <td>223.807478</td>\n",
       "      <td>322.116360</td>\n",
       "      <td>418.597665</td>\n",
       "      <td>418.597665</td>\n",
       "      <td>127.180023</td>\n",
       "      <td>-49.800064</td>\n",
       "      <td>318.352081</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>NCDeltaRadOverlaySM</td>\n",
       "      <td>1g0p</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6827</td>\n",
       "      <td>72</td>\n",
       "      <td>3635</td>\n",
       "      <td>220.771839</td>\n",
       "      <td>261.708669</td>\n",
       "      <td>346.037231</td>\n",
       "      <td>346.037231</td>\n",
       "      <td>218.050476</td>\n",
       "      <td>-41.677532</td>\n",
       "      <td>266.091003</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>NCDeltaRadOverlaySM</td>\n",
       "      <td>1g0p</td>\n",
       "      <td>pred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>11</td>\n",
       "      <td>15901</td>\n",
       "      <td>379</td>\n",
       "      <td>18996</td>\n",
       "      <td>86.929714</td>\n",
       "      <td>97.891710</td>\n",
       "      <td>95.735243</td>\n",
       "      <td>97.891710</td>\n",
       "      <td>188.837296</td>\n",
       "      <td>72.556511</td>\n",
       "      <td>936.094849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>12</td>\n",
       "      <td>14186</td>\n",
       "      <td>66</td>\n",
       "      <td>3336</td>\n",
       "      <td>18.964524</td>\n",
       "      <td>200.508582</td>\n",
       "      <td>174.618579</td>\n",
       "      <td>200.508582</td>\n",
       "      <td>200.712769</td>\n",
       "      <td>-18.161919</td>\n",
       "      <td>86.095505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>13</td>\n",
       "      <td>14736</td>\n",
       "      <td>179</td>\n",
       "      <td>8961</td>\n",
       "      <td>370.253497</td>\n",
       "      <td>240.394299</td>\n",
       "      <td>480.185831</td>\n",
       "      <td>480.185831</td>\n",
       "      <td>142.115280</td>\n",
       "      <td>-77.809120</td>\n",
       "      <td>923.357666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>14</td>\n",
       "      <td>15027</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>165.409022</td>\n",
       "      <td>185.473334</td>\n",
       "      <td>188.576298</td>\n",
       "      <td>188.576298</td>\n",
       "      <td>97.284668</td>\n",
       "      <td>-23.450846</td>\n",
       "      <td>523.709595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>15</td>\n",
       "      <td>16378</td>\n",
       "      <td>203</td>\n",
       "      <td>10180</td>\n",
       "      <td>133.786471</td>\n",
       "      <td>155.902559</td>\n",
       "      <td>161.875047</td>\n",
       "      <td>161.875047</td>\n",
       "      <td>83.437721</td>\n",
       "      <td>-109.118980</td>\n",
       "      <td>338.036163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5716 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry    run  subrun  event  reco_shower_energy_plane0  \\\n",
       "0         0   6058      81   4079                 288.261817   \n",
       "1         1   6058      81   4100                 118.919947   \n",
       "2         2   6221      10    537                 255.901477   \n",
       "3         3   6827      72   3605                 223.807478   \n",
       "4         4   6827      72   3635                 220.771839   \n",
       "...     ...    ...     ...    ...                        ...   \n",
       "5711     11  15901     379  18996                  86.929714   \n",
       "5712     12  14186      66   3336                  18.964524   \n",
       "5713     13  14736     179   8961                 370.253497   \n",
       "5714     14  15027       0     33                 165.409022   \n",
       "5715     15  16378     203  10180                 133.786471   \n",
       "\n",
       "      reco_shower_energy_plane1  reco_shower_energy_plane2  \\\n",
       "0                    310.056054                 309.773263   \n",
       "1                    189.828308                 220.959059   \n",
       "2                    291.085256                 320.449278   \n",
       "3                    322.116360                 418.597665   \n",
       "4                    261.708669                 346.037231   \n",
       "...                         ...                        ...   \n",
       "5711                  97.891710                  95.735243   \n",
       "5712                 200.508582                 174.618579   \n",
       "5713                 240.394299                 480.185831   \n",
       "5714                 185.473334                 188.576298   \n",
       "5715                 155.902559                 161.875047   \n",
       "\n",
       "      reco_shower_energy_max  reco_vertex_x  reco_vertex_y  reco_vertex_z  \\\n",
       "0                 310.056054     167.029160     -61.018150     387.096191   \n",
       "1                 220.959059     103.585838     -76.903328     578.505981   \n",
       "2                 320.449278     110.947716      28.835058     965.170654   \n",
       "3                 418.597665     127.180023     -49.800064     318.352081   \n",
       "4                 346.037231     218.050476     -41.677532     266.091003   \n",
       "...                      ...            ...            ...            ...   \n",
       "5711               97.891710     188.837296      72.556511     936.094849   \n",
       "5712              200.508582     200.712769     -18.161919      86.095505   \n",
       "5713              480.185831     142.115280     -77.809120     923.357666   \n",
       "5714              188.576298      97.284668     -23.450846     523.709595   \n",
       "5715              161.875047      83.437721    -109.118980     338.036163   \n",
       "\n",
       "      simple_pot_weight            glee_file glee_selection data_or_pred  \n",
       "0              0.000134  NCDeltaRadOverlaySM           1g0p         pred  \n",
       "1              0.000134  NCDeltaRadOverlaySM           1g0p         pred  \n",
       "2              0.000134  NCDeltaRadOverlaySM           1g0p         pred  \n",
       "3              0.000134  NCDeltaRadOverlaySM           1g0p         pred  \n",
       "4              0.000134  NCDeltaRadOverlaySM           1g0p         pred  \n",
       "...                 ...                  ...            ...          ...  \n",
       "5711           1.000000                 data           1g1p         data  \n",
       "5712           1.000000                 data           1g1p         data  \n",
       "5713           1.000000                 data           1g1p         data  \n",
       "5714           1.000000                 data           1g1p         data  \n",
       "5715           1.000000                 data           1g1p         data  \n",
       "\n",
       "[5716 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glee_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97667cb1-5a37-4638-accc-b7570b568e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# remove duplicate RSE nums, would be an issue when merging\\nglee_duplicate_row_list = glee_all_df[[\"run_number\", \"subrun_number\", \"event_number\"]].duplicated().to_numpy()\\nglee_duplicate_indices = list(np.nonzero(glee_duplicate_row_list)[0])\\nprint(glee_duplicate_indices)\\nglee_all_df.drop(glee_duplicate_indices, inplace=True)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if any RSE numbers are shared between glee files, would be an issue when merging\n",
    "\n",
    "prev_set = set()\n",
    "for i, row in glee_all_df.iterrows():\n",
    "    rse_num = row[\"run\"] * 1000000000000 + row[\"subrun\"] * 1000000 + row[\"event\"]\n",
    "    if rse_num in prev_set:\n",
    "        print(\"duplicate!\")\n",
    "        print(row[\"run\"], row[\"subrun\"], row[\"event\"], row[\"glee_file\"])\n",
    "    else:\n",
    "        prev_set.add(rse_num)\n",
    "        \n",
    "\"\"\"# remove duplicate RSE nums, would be an issue when merging\n",
    "glee_duplicate_row_list = glee_all_df[[\"run_number\", \"subrun_number\", \"event_number\"]].duplicated().to_numpy()\n",
    "glee_duplicate_indices = list(np.nonzero(glee_duplicate_row_list)[0])\n",
    "print(glee_duplicate_indices)\n",
    "glee_all_df.drop(glee_duplicate_indices, inplace=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6cd6023-7880-4d36-aff3-a78edbd1a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to load from WC files\n",
    "\n",
    "bdt_vars = [\n",
    "    \"nc_delta_score\",\n",
    "]\n",
    "\n",
    "extra_variables = [\n",
    "    \"run\",\n",
    "    \"subrun\",\n",
    "    \"event\",\n",
    "    \"nuvtx_diff\",\n",
    "    \"showervtx_diff\",\n",
    "    \"muonvtx_diff\",\n",
    "    \"truth_isCC\",\n",
    "    \"truth_vtxInside\",\n",
    "    \"truth_nuPdg\",\n",
    "    \"truth_nuEnergy\",\n",
    "    \"truth_nuIntType\",\n",
    "    \"truth_energyInside\",\n",
    "    \"weight_spline\",\n",
    "    \"weight_cv\",\n",
    "    \"weight_lee\",\n",
    "    \"event_type\",\n",
    "    \"weight\",\n",
    "    \"lowEweight\"\n",
    "]\n",
    "\n",
    "kine_scalar_vars = [\n",
    "    \"kine_reco_add_energy\",\n",
    "    \"kine_pio_mass\",\n",
    "    \"kine_pio_flag\",\n",
    "    \"kine_pio_vtx_dis\",\n",
    "    \"kine_pio_energy_1\",\n",
    "    \"kine_pio_theta_1\",\n",
    "    \"kine_pio_phi_1\",\n",
    "    \"kine_pio_dis_1\",\n",
    "    \"kine_pio_energy_2\",\n",
    "    \"kine_pio_theta_2\",\n",
    "    \"kine_pio_phi_2\",\n",
    "    \"kine_pio_dis_2\",\n",
    "    \"kine_pio_angle\"\n",
    "]\n",
    "\n",
    "kine_vector_vars = [\n",
    "    \"kine_energy_particle\",\n",
    "    \"kine_energy_info\",\n",
    "    \"kine_particle_type\",\n",
    "    \"kine_energy_included\",\n",
    "]\n",
    "\n",
    "eval_mc_variables = [\n",
    "    \"run\",\n",
    "    \"subrun\",\n",
    "    \"event\",\n",
    "    \"flash_time\",\n",
    "    \"weight_spline\", # this and remaining only make sense for MC\n",
    "    \"weight_cv\",\n",
    "    \"match_completeness_energy\",\n",
    "    \"truth_nuEnergy\",\n",
    "    \"truth_energyInside\",\n",
    "    \"truth_electronInside\",\n",
    "    \"truth_nuPdg\",\n",
    "    \"truth_isCC\",\n",
    "    \"truth_isFC\",\n",
    "    \"truth_vtxInside\",\n",
    "    \"truth_vtxX\",\n",
    "    \"truth_vtxY\",\n",
    "    \"truth_vtxZ\",\n",
    "    \"truth_nuTime\",\n",
    "]\n",
    "\n",
    "eval_data_variables = [\n",
    "    \"run\",\n",
    "    \"subrun\",\n",
    "    \"event\",\n",
    "    \"flash_time\",\n",
    "]\n",
    "\n",
    "\n",
    "pf_eval_mc_variables = [\n",
    "    \"truth_NprimPio\",\n",
    "    \"truth_NCDelta\",\n",
    "    \"nuvtx_diff\",\n",
    "    \"showervtx_diff\",\n",
    "    \"reco_showerKE\",\n",
    "    \"truth_pio_energy_1\",\n",
    "    \"truth_pio_energy_2\",\n",
    "    \"reco_nuvtxX\",\n",
    "    \"reco_nuvtxY\",\n",
    "    \"reco_nuvtxZ\",\n",
    "    \"reco_showervtxX\",\n",
    "    \"reco_showervtxY\",\n",
    "    \"reco_showervtxZ\",\n",
    "]\n",
    "\n",
    "pf_eval_data_variables = [ # also use these for dirt\n",
    "    \"reco_showerKE\",\n",
    "    \"reco_nuvtxX\",\n",
    "    \"reco_nuvtxY\",\n",
    "    \"reco_nuvtxZ\",\n",
    "    \"reco_showervtxX\",\n",
    "    \"reco_showervtxY\",\n",
    "    \"reco_showervtxZ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23129744-773f-4a46-983e-a7330b23c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1819002904629175e+23\n",
      "47482\n",
      "4.7398996193248585e+23\n",
      "101199\n",
      "5.14123404156446e+23\n",
      "109843\n"
     ]
    }
   ],
   "source": [
    "# loading WC NC Delta files\n",
    "\n",
    "f_nc_delta_run1 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nc_delta_overlay_run1_PF.root\")[\"wcpselection\"]\n",
    "#print(f_nc_delta_run1.keys())\n",
    "#f_nc_delta_run1[\"T_KINEvars\"].show()\n",
    "f_nc_delta_run1_bdt = f_nc_delta_run1[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_nc_delta_run1_eval = f_nc_delta_run1[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_nc_delta_run1_pfeval = f_nc_delta_run1[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_nc_delta_run1_kine = f_nc_delta_run1[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_nc_delta_run1_pot = f_nc_delta_run1[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nc_delta_run1_file_POT = np.sum(f_nc_delta_run1_pot[\"pot_tor875good\"].to_numpy())\n",
    "nc_delta_run1_df = pd.concat([f_nc_delta_run1_bdt, f_nc_delta_run1_eval, f_nc_delta_run1_pfeval, f_nc_delta_run1_kine], axis=1, sort=False)\n",
    "del f_nc_delta_run1\n",
    "del f_nc_delta_run1_bdt\n",
    "del f_nc_delta_run1_eval\n",
    "del f_nc_delta_run1_pfeval\n",
    "del f_nc_delta_run1_kine\n",
    "del f_nc_delta_run1_pot\n",
    "nc_delta_run1_df[\"isEXT\"] = [0 for i in range(nc_delta_run1_df.shape[0])]\n",
    "nc_delta_run1_df[\"isDirt\"] = [0 for i in range(nc_delta_run1_df.shape[0])]\n",
    "nc_delta_run1_df[\"WC_file\"] = [\"nc_delta_run1\" for i in range(nc_delta_run1_df.shape[0])]\n",
    "nc_delta_run1_df[\"run_num\"] = [1 for i in range(nc_delta_run1_df.shape[0])]\n",
    "\n",
    "print(nc_delta_run1_file_POT)\n",
    "print(nc_delta_run1_df.shape[0])\n",
    "\n",
    "f_nc_delta_run2 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nc_delta_overlay_run2_PF.root\")[\"wcpselection\"]\n",
    "f_nc_delta_run2_bdt = f_nc_delta_run2[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_nc_delta_run2_eval = f_nc_delta_run2[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_nc_delta_run2_pfeval = f_nc_delta_run2[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_nc_delta_run2_kine = f_nc_delta_run2[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_nc_delta_run2_pot = f_nc_delta_run2[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nc_delta_run2_file_POT = np.sum(f_nc_delta_run2_pot[\"pot_tor875good\"].to_numpy())\n",
    "nc_delta_run2_df = pd.concat([f_nc_delta_run2_bdt, f_nc_delta_run2_eval, f_nc_delta_run2_pfeval, f_nc_delta_run2_kine], axis=1, sort=False)\n",
    "del f_nc_delta_run2\n",
    "del f_nc_delta_run2_bdt\n",
    "del f_nc_delta_run2_eval\n",
    "del f_nc_delta_run2_pfeval\n",
    "del f_nc_delta_run2_kine\n",
    "del f_nc_delta_run2_pot\n",
    "nc_delta_run2_df[\"isEXT\"] = [0 for i in range(nc_delta_run2_df.shape[0])]\n",
    "nc_delta_run2_df[\"isDirt\"] = [0 for i in range(nc_delta_run2_df.shape[0])]\n",
    "nc_delta_run2_df[\"WC_file\"] = [\"nc_delta_run2\" for i in range(nc_delta_run2_df.shape[0])]\n",
    "nc_delta_run2_df[\"run_num\"] = [2 for i in range(nc_delta_run2_df.shape[0])]\n",
    "\n",
    "print(nc_delta_run2_file_POT)\n",
    "print(nc_delta_run2_df.shape[0])\n",
    "\n",
    "f_nc_delta_run3 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nc_delta_overlay_run3_PF.root\")[\"wcpselection\"]\n",
    "f_nc_delta_run3_bdt = f_nc_delta_run3[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_nc_delta_run3_eval = f_nc_delta_run3[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_nc_delta_run3_pfeval = f_nc_delta_run3[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_nc_delta_run3_kine = f_nc_delta_run3[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_nc_delta_run3_pot = f_nc_delta_run3[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nc_delta_run3_file_POT = np.sum(f_nc_delta_run3_pot[\"pot_tor875good\"].to_numpy())\n",
    "nc_delta_run3_df = pd.concat([f_nc_delta_run3_bdt, f_nc_delta_run3_eval, f_nc_delta_run3_pfeval, f_nc_delta_run3_kine], axis=1, sort=False)\n",
    "del f_nc_delta_run3\n",
    "del f_nc_delta_run3_bdt\n",
    "del f_nc_delta_run3_eval\n",
    "del f_nc_delta_run3_pfeval\n",
    "del f_nc_delta_run3_kine\n",
    "del f_nc_delta_run3_pot\n",
    "nc_delta_run3_df[\"isEXT\"] = [0 for i in range(nc_delta_run3_df.shape[0])]\n",
    "nc_delta_run3_df[\"isDirt\"] = [0 for i in range(nc_delta_run3_df.shape[0])]\n",
    "nc_delta_run3_df[\"WC_file\"] = [\"nc_delta_run3\" for i in range(nc_delta_run3_df.shape[0])]\n",
    "nc_delta_run3_df[\"run_num\"] = [3 for i in range(nc_delta_run3_df.shape[0])]\n",
    "\n",
    "print(nc_delta_run3_file_POT)\n",
    "print(nc_delta_run3_df.shape[0])\n",
    "\n",
    "nc_delta_df = pd.concat([nc_delta_run1_df, nc_delta_run2_df, nc_delta_run3_df], sort=False).query(\"truth_isCC==0 and truth_NCDelta==1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b38fd3b-1642-4928-9fe6-66013629b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.224676151063279e+21\n",
      "48005\n",
      "1.2277865498371458e+21\n",
      "47066\n"
     ]
    }
   ],
   "source": [
    "# loading WC NC Pi0 files\n",
    "\n",
    "f_ncpi0_run1 = uproot.open(wc_file_location + \"checkout_prodgenie_nc_pi0_overlay_run1_PF.root\")[\"wcpselection\"]\n",
    "f_ncpi0_run1_bdt = f_ncpi0_run1[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_ncpi0_run1_eval = f_ncpi0_run1[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_ncpi0_run1_pfeval = f_ncpi0_run1[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_ncpi0_run1_kine = f_ncpi0_run1[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_ncpi0_run1_pot = f_ncpi0_run1[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nc_pi0_run1_file_POT = np.sum(f_ncpi0_run1_pot[\"pot_tor875good\"].to_numpy())\n",
    "nc_pi0_run1_df = pd.concat([f_ncpi0_run1_bdt, f_ncpi0_run1_eval, f_ncpi0_run1_pfeval, f_ncpi0_run1_kine], axis=1, sort=False)\n",
    "del f_ncpi0_run1\n",
    "del f_ncpi0_run1_bdt\n",
    "del f_ncpi0_run1_eval\n",
    "del f_ncpi0_run1_pfeval\n",
    "del f_ncpi0_run1_kine\n",
    "del f_ncpi0_run1_pot\n",
    "nc_pi0_run1_df[\"isEXT\"] = [0 for i in range(nc_pi0_run1_df.shape[0])]\n",
    "nc_pi0_run1_df[\"isDirt\"] = [0 for i in range(nc_pi0_run1_df.shape[0])]\n",
    "nc_pi0_run1_df[\"WC_file\"] = [\"NC_Pi0_run1\" for i in range(nc_pi0_run1_df.shape[0])]\n",
    "nc_pi0_run1_df[\"run_num\"] = [1 for i in range(nc_pi0_run1_df.shape[0])]\n",
    "\n",
    "f_ncpi0_run2 = uproot.open(wc_file_location + \"checkout_prodgenie_nc_pi0_overlay_run2_PF.root\")[\"wcpselection\"]\n",
    "f_ncpi0_run2_bdt = f_ncpi0_run2[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_ncpi0_run2_eval = f_ncpi0_run2[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_ncpi0_run2_pfeval = f_ncpi0_run2[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_ncpi0_run2_kine = f_ncpi0_run2[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_ncpi0_run2_pot = f_ncpi0_run2[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nc_pi0_run2_file_POT = np.sum(f_ncpi0_run2_pot[\"pot_tor875good\"].to_numpy())\n",
    "nc_pi0_run2_df = pd.concat([f_ncpi0_run2_bdt, f_ncpi0_run2_eval, f_ncpi0_run2_pfeval, f_ncpi0_run2_kine], axis=1, sort=False)\n",
    "del f_ncpi0_run2\n",
    "del f_ncpi0_run2_bdt\n",
    "del f_ncpi0_run2_eval\n",
    "del f_ncpi0_run2_pfeval\n",
    "del f_ncpi0_run2_kine\n",
    "del f_ncpi0_run2_pot\n",
    "nc_pi0_run2_df[\"isEXT\"] = [0 for i in range(nc_pi0_run2_df.shape[0])]\n",
    "nc_pi0_run2_df[\"isDirt\"] = [0 for i in range(nc_pi0_run2_df.shape[0])]\n",
    "nc_pi0_run2_df[\"WC_file\"] = [\"NC_Pi0_run2\" for i in range(nc_pi0_run2_df.shape[0])]\n",
    "nc_pi0_run2_df[\"run_num\"] = [2 for i in range(nc_pi0_run2_df.shape[0])]\n",
    "\n",
    "\n",
    "f_ncpi0_run3 = uproot.open(wc_file_location + \"checkout_prodgenie_nc_pi0_overlay_run3_PF.root\")[\"wcpselection\"]\n",
    "f_ncpi0_run3_bdt = f_ncpi0_run3[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_ncpi0_run3_eval = f_ncpi0_run3[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_ncpi0_run3_pfeval = f_ncpi0_run3[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_ncpi0_run3_kine = f_ncpi0_run3[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_ncpi0_run3_pot = f_ncpi0_run3[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nc_pi0_run3_file_POT = np.sum(f_ncpi0_run3_pot[\"pot_tor875good\"].to_numpy())\n",
    "nc_pi0_run3_df = pd.concat([f_ncpi0_run3_bdt, f_ncpi0_run3_eval, f_ncpi0_run3_pfeval, f_ncpi0_run3_kine], axis=1, sort=False)\n",
    "del f_ncpi0_run3\n",
    "del f_ncpi0_run3_bdt\n",
    "del f_ncpi0_run3_eval\n",
    "del f_ncpi0_run3_pfeval\n",
    "del f_ncpi0_run3_kine\n",
    "del f_ncpi0_run3_pot\n",
    "nc_pi0_run3_df[\"isEXT\"] = [0 for i in range(nc_pi0_run3_df.shape[0])]\n",
    "nc_pi0_run3_df[\"isDirt\"] = [0 for i in range(nc_pi0_run3_df.shape[0])]\n",
    "nc_pi0_run3_df[\"WC_file\"] = [\"NC_Pi0_run3\" for i in range(nc_pi0_run3_df.shape[0])]\n",
    "nc_pi0_run3_df[\"run_num\"] = [3 for i in range(nc_pi0_run3_df.shape[0])]\n",
    "\n",
    "print(nc_pi0_run1_file_POT)\n",
    "print(nc_pi0_run1_df.shape[0])\n",
    "\n",
    "print(nc_pi0_run3_file_POT)\n",
    "print(nc_pi0_run3_df.shape[0])\n",
    "\n",
    "nc_pi0_df = pd.concat([nc_pi0_run1_df, nc_pi0_run2_df, nc_pi0_run3_df], sort=False).query(\"truth_isCC==0 and truth_NprimPio>0 and not (truth_NCDelta==1)\")\n",
    "\n",
    "del nc_pi0_run1_df\n",
    "del nc_pi0_run2_df\n",
    "del nc_pi0_run3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e3ccca-7eb7-4620-a351-ea70416a7777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.931094470783121e+22\n",
      "68206\n",
      "1.2460289446544576e+23\n",
      "209160\n",
      "8.821478522260567e+22\n",
      "148962\n"
     ]
    }
   ],
   "source": [
    "# loading WC nue overlay files\n",
    "\n",
    "f_intrinsic_nue_run1 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_intrinsic_nue_overlay_run1_PF.root\")[\"wcpselection\"]\n",
    "f_intrinsic_nue_run1_bdt = f_intrinsic_nue_run1[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_intrinsic_nue_run1_eval = f_intrinsic_nue_run1[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_intrinsic_nue_run1_pfeval = f_intrinsic_nue_run1[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_intrinsic_nue_run1_kine = f_intrinsic_nue_run1[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_intrinsic_nue_run1_pot = f_intrinsic_nue_run1[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "intrinsic_nue_run1_file_POT = np.sum(f_intrinsic_nue_run1_pot[\"pot_tor875good\"].to_numpy())\n",
    "intrinsic_nue_run1_df = pd.concat([f_intrinsic_nue_run1_bdt, f_intrinsic_nue_run1_eval, f_intrinsic_nue_run1_pfeval, f_intrinsic_nue_run1_kine], axis=1, sort=False)\n",
    "del f_intrinsic_nue_run1\n",
    "del f_intrinsic_nue_run1_bdt\n",
    "del f_intrinsic_nue_run1_eval\n",
    "del f_intrinsic_nue_run1_pfeval\n",
    "del f_intrinsic_nue_run1_kine\n",
    "del f_intrinsic_nue_run1_pot\n",
    "intrinsic_nue_run1_df[\"isEXT\"] = [0 for i in range(intrinsic_nue_run1_df.shape[0])]\n",
    "intrinsic_nue_run1_df[\"isDirt\"] = [0 for i in range(intrinsic_nue_run1_df.shape[0])]\n",
    "intrinsic_nue_run1_df[\"WC_file\"] = [\"intrinsic_nue_run1\" for i in range(intrinsic_nue_run1_df.shape[0])]\n",
    "intrinsic_nue_run1_df[\"run_num\"] = [1 for i in range(intrinsic_nue_run1_df.shape[0])]\n",
    "\n",
    "print(intrinsic_nue_run1_file_POT)\n",
    "print(intrinsic_nue_run1_df.shape[0])\n",
    "\n",
    "f_intrinsic_nue_run2 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_intrinsic_nue_overlay_run2_PF.root\")[\"wcpselection\"]\n",
    "f_intrinsic_nue_run2_bdt = f_intrinsic_nue_run2[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_intrinsic_nue_run2_eval = f_intrinsic_nue_run2[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_intrinsic_nue_run2_pfeval = f_intrinsic_nue_run2[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_intrinsic_nue_run2_kine = f_intrinsic_nue_run2[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_intrinsic_nue_run2_pot = f_intrinsic_nue_run2[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "intrinsic_nue_run2_file_POT = np.sum(f_intrinsic_nue_run2_pot[\"pot_tor875good\"].to_numpy())\n",
    "intrinsic_nue_run2_df = pd.concat([f_intrinsic_nue_run2_bdt, f_intrinsic_nue_run2_eval, f_intrinsic_nue_run2_pfeval, f_intrinsic_nue_run2_kine], axis=1, sort=False)\n",
    "del f_intrinsic_nue_run2\n",
    "del f_intrinsic_nue_run2_bdt\n",
    "del f_intrinsic_nue_run2_eval\n",
    "del f_intrinsic_nue_run2_pfeval\n",
    "del f_intrinsic_nue_run2_kine\n",
    "del f_intrinsic_nue_run2_pot\n",
    "intrinsic_nue_run2_df[\"isEXT\"] = [0 for i in range(intrinsic_nue_run2_df.shape[0])]\n",
    "intrinsic_nue_run2_df[\"isDirt\"] = [0 for i in range(intrinsic_nue_run2_df.shape[0])]\n",
    "intrinsic_nue_run2_df[\"WC_file\"] = [\"intrinsic_nue_run2\" for i in range(intrinsic_nue_run2_df.shape[0])]\n",
    "intrinsic_nue_run2_df[\"run_num\"] = [2 for i in range(intrinsic_nue_run2_df.shape[0])]\n",
    "\n",
    "print(intrinsic_nue_run2_file_POT)\n",
    "print(intrinsic_nue_run2_df.shape[0])\n",
    "\n",
    "f_intrinsic_nue_run3 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_intrinsic_nue_overlay_run3_PF.root\")[\"wcpselection\"]\n",
    "f_intrinsic_nue_run3_bdt = f_intrinsic_nue_run3[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_intrinsic_nue_run3_eval = f_intrinsic_nue_run3[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_intrinsic_nue_run3_pfeval = f_intrinsic_nue_run3[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_intrinsic_nue_run3_kine = f_intrinsic_nue_run3[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_intrinsic_nue_run3_pot = f_intrinsic_nue_run3[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "intrinsic_nue_run3_file_POT = np.sum(f_intrinsic_nue_run3_pot[\"pot_tor875good\"].to_numpy())\n",
    "intrinsic_nue_run3_df = pd.concat([f_intrinsic_nue_run3_bdt, f_intrinsic_nue_run3_eval, f_intrinsic_nue_run3_pfeval, f_intrinsic_nue_run3_kine], axis=1, sort=False)\n",
    "del f_intrinsic_nue_run3\n",
    "del f_intrinsic_nue_run3_bdt\n",
    "del f_intrinsic_nue_run3_eval\n",
    "del f_intrinsic_nue_run3_pfeval\n",
    "del f_intrinsic_nue_run3_kine\n",
    "del f_intrinsic_nue_run3_pot\n",
    "intrinsic_nue_run3_df[\"isEXT\"] = [0 for i in range(intrinsic_nue_run3_df.shape[0])]\n",
    "intrinsic_nue_run3_df[\"isDirt\"] = [0 for i in range(intrinsic_nue_run3_df.shape[0])]\n",
    "intrinsic_nue_run3_df[\"WC_file\"] = [\"intrinsic_nue_run3\" for i in range(intrinsic_nue_run3_df.shape[0])]\n",
    "intrinsic_nue_run3_df[\"run_num\"] = [3 for i in range(intrinsic_nue_run3_df.shape[0])]\n",
    "\n",
    "print(intrinsic_nue_run3_file_POT)\n",
    "print(intrinsic_nue_run3_df.shape[0])\n",
    "\n",
    "intrinsic_nue_df = pd.concat([intrinsic_nue_run1_df, intrinsic_nue_run2_df, intrinsic_nue_run3_df], sort=False).query(\n",
    "    \"truth_isCC==1 and abs(truth_nuPdg)==12\")\n",
    "\n",
    "del intrinsic_nue_run1_df\n",
    "del intrinsic_nue_run2_df\n",
    "del intrinsic_nue_run3_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7639e292-ae9c-4105-8148-9fcffa6aa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading WC nu overlay files\n",
    "\n",
    "f_nu_overlay_run1 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nu_overlay_run1_PF.root\")[\"wcpselection\"]\n",
    "f_nu_overlay_run1_bdt = f_nu_overlay_run1[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_nu_overlay_run1_eval = f_nu_overlay_run1[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_nu_overlay_run1_pfeval = f_nu_overlay_run1[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_nu_overlay_run1_kine = f_nu_overlay_run1[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_nu_overlay_run1_pot = f_nu_overlay_run1[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nu_overlay_run1_POT = np.sum(f_nu_overlay_run1_pot[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run1_df = pd.concat([f_nu_overlay_run1_bdt, f_nu_overlay_run1_eval, f_nu_overlay_run1_pfeval, f_nu_overlay_run1_kine], axis=1, sort=False)\n",
    "del f_nu_overlay_run1\n",
    "del f_nu_overlay_run1_bdt\n",
    "del f_nu_overlay_run1_eval\n",
    "del f_nu_overlay_run1_pfeval\n",
    "del f_nu_overlay_run1_kine\n",
    "del f_nu_overlay_run1_pot\n",
    "nu_overlay_run1_df[\"isEXT\"] = [0 for i in range(nu_overlay_run1_df.shape[0])]\n",
    "nu_overlay_run1_df[\"isDirt\"] = [0 for i in range(nu_overlay_run1_df.shape[0])]\n",
    "nu_overlay_run1_df[\"WC_file\"] = [\"nu_overlay_run1\" for i in range(nu_overlay_run1_df.shape[0])]\n",
    "nu_overlay_run1_df[\"run_num\"] = [1 for i in range(nu_overlay_run1_df.shape[0])]\n",
    "\n",
    "f_nu_overlay_run2 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nu_overlay_run2_PF.root\")[\"wcpselection\"]\n",
    "f_nu_overlay_run2_bdt = f_nu_overlay_run2[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_nu_overlay_run2_eval = f_nu_overlay_run2[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_nu_overlay_run2_pfeval = f_nu_overlay_run2[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_nu_overlay_run2_kine = f_nu_overlay_run2[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_nu_overlay_run2_pot = f_nu_overlay_run2[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nu_overlay_run2_POT = np.sum(f_nu_overlay_run2_pot[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run2_df = pd.concat([f_nu_overlay_run2_bdt, f_nu_overlay_run2_eval, f_nu_overlay_run2_pfeval, f_nu_overlay_run2_kine], axis=1, sort=False)\n",
    "del f_nu_overlay_run2\n",
    "del f_nu_overlay_run2_bdt\n",
    "del f_nu_overlay_run2_eval\n",
    "del f_nu_overlay_run2_pfeval\n",
    "del f_nu_overlay_run2_kine\n",
    "del f_nu_overlay_run2_pot\n",
    "nu_overlay_run2_df[\"isEXT\"] = [0 for i in range(nu_overlay_run2_df.shape[0])]\n",
    "nu_overlay_run2_df[\"isDirt\"] = [0 for i in range(nu_overlay_run2_df.shape[0])]\n",
    "nu_overlay_run2_df[\"WC_file\"] = [\"nu_overlay_run2\" for i in range(nu_overlay_run2_df.shape[0])]\n",
    "nu_overlay_run2_df[\"run_num\"] = [2 for i in range(nu_overlay_run2_df.shape[0])]\n",
    "\n",
    "f_nu_overlay_run3 = uproot.open(wc_file_location + \"checkout_prodgenie_bnb_nu_overlay_run3_PF.root\")[\"wcpselection\"]\n",
    "f_nu_overlay_run3_bdt = f_nu_overlay_run3[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_nu_overlay_run3_eval = f_nu_overlay_run3[\"T_eval\"].pandas.df(eval_mc_variables + [\"match_isFC\"], flatten=False)\n",
    "f_nu_overlay_run3_pfeval = f_nu_overlay_run3[\"T_PFeval\"].pandas.df(pf_eval_mc_variables, flatten=False)\n",
    "f_nu_overlay_run3_kine = f_nu_overlay_run3[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_nu_overlay_run3_pot = f_nu_overlay_run3[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "nu_overlay_run3_POT = np.sum(f_nu_overlay_run3_pot[\"pot_tor875good\"].to_numpy())\n",
    "nu_overlay_run3_df = pd.concat([f_nu_overlay_run3_bdt, f_nu_overlay_run3_eval, f_nu_overlay_run3_pfeval, f_nu_overlay_run3_kine], axis=1, sort=False)\n",
    "del f_nu_overlay_run3\n",
    "del f_nu_overlay_run3_bdt\n",
    "del f_nu_overlay_run3_eval\n",
    "del f_nu_overlay_run3_pfeval\n",
    "del f_nu_overlay_run3_kine\n",
    "del f_nu_overlay_run3_pot\n",
    "nu_overlay_run3_df[\"isEXT\"] = [0 for i in range(nu_overlay_run3_df.shape[0])]\n",
    "nu_overlay_run3_df[\"isDirt\"] = [0 for i in range(nu_overlay_run3_df.shape[0])]\n",
    "nu_overlay_run3_df[\"WC_file\"] = [\"nu_overlay_run3\" for i in range(nu_overlay_run3_df.shape[0])]\n",
    "nu_overlay_run3_df[\"run_num\"] = [3 for i in range(nu_overlay_run3_df.shape[0])]\n",
    "\n",
    "overlay_df = pd.concat([nu_overlay_run1_df, nu_overlay_run2_df, nu_overlay_run3_df], sort=False).query(\n",
    "    \"not (truth_isCC==0 and truth_NCDelta==1) and not (truth_isCC==0 and truth_NprimPio>0 and not (truth_NCDelta==1)) and not (truth_isCC==1 and abs(truth_nuPdg)==12)\")\n",
    "del nu_overlay_run1_df\n",
    "del nu_overlay_run2_df\n",
    "del nu_overlay_run3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21c4ed0a-0601-4646-8e96-b332eaf38671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading WC EXT files\n",
    "\n",
    "f_ext_run1 = uproot.open(wc_file_location + \"wcp_data_extbnb_run1_mcc9_v08_00_00_53_checkout.root\")[\"wcpselection\"]\n",
    "f_ext_run1_bdt = f_ext_run1[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_ext_run1_eval = f_ext_run1[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_ext_run1_pfeval = f_ext_run1[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_ext_run1_kine = f_ext_run1[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_ext_run1_pot = f_ext_run1[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "ext_run1_POT = np.sum(f_ext_run1_pot[\"pot_tor875good\"].to_numpy())\n",
    "ext_run1_df = pd.concat([f_ext_run1_bdt, f_ext_run1_eval, f_ext_run1_pfeval, f_ext_run1_kine], axis=1, sort=False)\n",
    "del f_ext_run1\n",
    "del f_ext_run1_bdt\n",
    "del f_ext_run1_eval\n",
    "del f_ext_run1_pfeval\n",
    "del f_ext_run1_kine\n",
    "del f_ext_run1_pot\n",
    "ext_run1_df[\"isEXT\"] = [1 for i in range(ext_run1_df.shape[0])]\n",
    "ext_run1_df[\"isDirt\"] = [0 for i in range(ext_run1_df.shape[0])]\n",
    "ext_run1_df[\"WC_file\"] = [\"ext_run1\" for i in range(ext_run1_df.shape[0])]\n",
    "ext_run1_df[\"run_num\"] = [1 for i in range(ext_run1_df.shape[0])]\n",
    "\n",
    "f_ext_run2 = uproot.open(wc_file_location + \"wcp_data_extbnb_run2_mcc9_v08_00_00_53_checkout.root\")[\"wcpselection\"]\n",
    "f_ext_run2_bdt = f_ext_run2[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_ext_run2_eval = f_ext_run2[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_ext_run2_pfeval = f_ext_run2[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_ext_run2_kine = f_ext_run2[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_ext_run2_pot = f_ext_run2[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "ext_run2_POT = np.sum(f_ext_run2_pot[\"pot_tor875good\"].to_numpy())\n",
    "ext_run2_df = pd.concat([f_ext_run2_bdt, f_ext_run2_eval, f_ext_run2_pfeval, f_ext_run2_kine], axis=1, sort=False)\n",
    "del f_ext_run2\n",
    "del f_ext_run2_bdt\n",
    "del f_ext_run2_eval\n",
    "del f_ext_run2_pfeval\n",
    "del f_ext_run2_kine\n",
    "del f_ext_run2_pot\n",
    "ext_run2_df[\"isEXT\"] = [1 for i in range(ext_run2_df.shape[0])]\n",
    "ext_run2_df[\"isDirt\"] = [0 for i in range(ext_run2_df.shape[0])]\n",
    "ext_run2_df[\"WC_file\"] = [\"ext_run2\" for i in range(ext_run2_df.shape[0])]\n",
    "ext_run2_df[\"run_num\"] = [2 for i in range(ext_run2_df.shape[0])]\n",
    "\n",
    "f_ext_run3 = uproot.open(wc_file_location + \"wcp_data_extbnb_run3_mcc9_v08_00_00_53_checkout.root\")[\"wcpselection\"]\n",
    "f_ext_run3_bdt = f_ext_run3[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_ext_run3_eval = f_ext_run3[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_ext_run3_pfeval = f_ext_run3[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_ext_run3_kine = f_ext_run3[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_ext_run3_pot = f_ext_run3[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "ext_run3_POT = np.sum(f_ext_run3_pot[\"pot_tor875good\"].to_numpy())\n",
    "ext_run3_df = pd.concat([f_ext_run3_bdt, f_ext_run3_eval, f_ext_run3_pfeval, f_ext_run3_kine], axis=1, sort=False)\n",
    "del f_ext_run3\n",
    "del f_ext_run3_bdt\n",
    "del f_ext_run3_eval\n",
    "del f_ext_run3_pfeval\n",
    "del f_ext_run3_kine\n",
    "del f_ext_run3_pot\n",
    "ext_run3_df[\"isEXT\"] = [1 for i in range(ext_run3_df.shape[0])]\n",
    "ext_run3_df[\"isDirt\"] = [0 for i in range(ext_run3_df.shape[0])]\n",
    "ext_run3_df[\"WC_file\"] = [\"ext_run3\" for i in range(ext_run3_df.shape[0])]\n",
    "ext_run3_df[\"run_num\"] = [3 for i in range(ext_run3_df.shape[0])]\n",
    "\n",
    "ext_df = pd.concat([ext_run1_df, ext_run2_df, ext_run3_df], sort=False)\n",
    "del ext_run1_df\n",
    "del ext_run2_df\n",
    "del ext_run3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc57170-831d-4ac5-b7f0-a4f28f66441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading WC dirt files\n",
    "\n",
    "f_dirt_run1 = uproot.open(wc_file_location + \"checkout_prodgenie_dirt_overlay_run1_all.root\")[\"wcpselection\"]\n",
    "f_dirt_run1_bdt = f_dirt_run1[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_dirt_run1_eval = f_dirt_run1[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_dirt_run1_pfeval = f_dirt_run1[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_dirt_run1_kine = f_dirt_run1[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_dirt_run1_pot = f_dirt_run1[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "dirt_run1_POT = np.sum(f_dirt_run1_pot[\"pot_tor875good\"].to_numpy())\n",
    "dirt_run1_df = pd.concat([f_dirt_run1_bdt, f_dirt_run1_eval, f_dirt_run1_pfeval, f_dirt_run1_kine], axis=1, sort=False)\n",
    "del f_dirt_run1\n",
    "del f_dirt_run1_bdt\n",
    "del f_dirt_run1_eval\n",
    "del f_dirt_run1_pfeval\n",
    "del f_dirt_run1_kine\n",
    "del f_dirt_run1_pot\n",
    "dirt_run1_df[\"isEXT\"] = [0 for i in range(dirt_run1_df.shape[0])]\n",
    "dirt_run1_df[\"isDirt\"] = [1 for i in range(dirt_run1_df.shape[0])]\n",
    "dirt_run1_df[\"WC_file\"] = [\"dirt_run1\" for i in range(dirt_run1_df.shape[0])]\n",
    "dirt_run1_df[\"run_num\"] = [1 for i in range(dirt_run1_df.shape[0])]\n",
    "\n",
    "f_dirt_run2 = uproot.open(wc_file_location + \"checkout_prodgenie_dirt_overlay_run2_all.root\")[\"wcpselection\"]\n",
    "f_dirt_run2_bdt = f_dirt_run2[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_dirt_run2_eval = f_dirt_run2[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_dirt_run2_pfeval = f_dirt_run2[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_dirt_run2_kine = f_dirt_run2[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_dirt_run2_pot = f_dirt_run2[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "dirt_run2_POT = np.sum(f_dirt_run2_pot[\"pot_tor875good\"].to_numpy())\n",
    "dirt_run2_df = pd.concat([f_dirt_run2_bdt, f_dirt_run2_eval, f_dirt_run2_pfeval, f_dirt_run2_kine], axis=1, sort=False)\n",
    "del f_dirt_run2\n",
    "del f_dirt_run2_bdt\n",
    "del f_dirt_run2_eval\n",
    "del f_dirt_run2_pfeval\n",
    "del f_dirt_run2_kine\n",
    "del f_dirt_run2_pot\n",
    "dirt_run2_df[\"isEXT\"] = [0 for i in range(dirt_run2_df.shape[0])]\n",
    "dirt_run2_df[\"isDirt\"] = [1 for i in range(dirt_run2_df.shape[0])]\n",
    "dirt_run2_df[\"WC_file\"] = [\"dirt_run2\" for i in range(dirt_run2_df.shape[0])]\n",
    "dirt_run2_df[\"run_num\"] = [2 for i in range(dirt_run2_df.shape[0])]\n",
    "\n",
    "f_dirt_run3 = uproot.open(wc_file_location + \"checkout_prodgenie_dirt_overlay_run3_all.root\")[\"wcpselection\"]\n",
    "f_dirt_run3_bdt = f_dirt_run3[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_dirt_run3_eval = f_dirt_run3[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_dirt_run3_pfeval = f_dirt_run3[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_dirt_run3_kine = f_dirt_run3[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "f_dirt_run3_pot = f_dirt_run3[\"T_pot\"].pandas.df(\"pot_tor875good\", flatten=False)\n",
    "dirt_run3_POT = np.sum(f_dirt_run3_pot[\"pot_tor875good\"].to_numpy())\n",
    "dirt_run3_df = pd.concat([f_dirt_run3_bdt, f_dirt_run3_eval, f_dirt_run3_pfeval, f_dirt_run3_kine], axis=1, sort=False)\n",
    "del f_dirt_run3\n",
    "del f_dirt_run3_bdt\n",
    "del f_dirt_run3_eval\n",
    "del f_dirt_run3_pfeval\n",
    "del f_dirt_run3_kine\n",
    "del f_dirt_run3_pot\n",
    "dirt_run3_df[\"isEXT\"] = [0 for i in range(dirt_run3_df.shape[0])]\n",
    "dirt_run3_df[\"isDirt\"] = [1 for i in range(dirt_run3_df.shape[0])]\n",
    "dirt_run3_df[\"WC_file\"] = [\"dirt_run3\" for i in range(dirt_run3_df.shape[0])]\n",
    "dirt_run3_df[\"run_num\"] = [3 for i in range(dirt_run3_df.shape[0])]\n",
    "\n",
    "dirt_df = pd.concat([dirt_run1_df, dirt_run2_df, dirt_run3_df], sort=False)\n",
    "del dirt_run1_df\n",
    "del dirt_run2_df\n",
    "del dirt_run3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb34c9e-17aa-43f1-a62f-4a424fc1d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data\n",
    "\n",
    "f_data_run1 = uproot.open(wc_file_location + \"checkout_data_bnb_run1_all.root\")[\"wcpselection\"]\n",
    "f_data_run1_bdt = f_data_run1[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_data_run1_eval = f_data_run1[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_data_run1_pfeval = f_data_run1[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_data_run1_kine = f_data_run1[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "data_run1_df = pd.concat([f_data_run1_bdt, f_data_run1_eval, f_data_run1_pfeval, f_data_run1_kine], axis=1, sort=False)\n",
    "del f_data_run1\n",
    "del f_data_run1_bdt\n",
    "del f_data_run1_eval\n",
    "del f_data_run1_pfeval\n",
    "del f_data_run1_kine\n",
    "data_run1_df[\"isEXT\"] = [0 for i in range(data_run1_df.shape[0])]\n",
    "data_run1_df[\"isDirt\"] = [0 for i in range(data_run1_df.shape[0])]\n",
    "data_run1_df[\"WC_file\"] = [\"data_run1\" for i in range(data_run1_df.shape[0])]\n",
    "data_run1_df[\"category\"] = [\"data\" for i in range(data_run1_df.shape[0])]\n",
    "data_run1_df[\"run_num\"] = [1 for i in range(data_run1_df.shape[0])]\n",
    "\n",
    "f_data_run2 = uproot.open(wc_file_location + \"checkout_data_bnb_run2_all.root\")[\"wcpselection\"]\n",
    "f_data_run2_bdt = f_data_run2[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_data_run2_eval = f_data_run2[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_data_run2_pfeval = f_data_run2[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_data_run2_kine = f_data_run2[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "data_run2_df = pd.concat([f_data_run2_bdt, f_data_run2_eval, f_data_run2_pfeval, f_data_run2_kine], axis=1, sort=False)\n",
    "del f_data_run2\n",
    "del f_data_run2_bdt\n",
    "del f_data_run2_eval\n",
    "del f_data_run2_pfeval\n",
    "del f_data_run2_kine\n",
    "data_run2_df[\"isEXT\"] = [0 for i in range(data_run2_df.shape[0])]\n",
    "data_run2_df[\"isDirt\"] = [0 for i in range(data_run2_df.shape[0])]\n",
    "data_run2_df[\"WC_file\"] = [\"data_run2\" for i in range(data_run2_df.shape[0])]\n",
    "data_run2_df[\"category\"] = [\"data\" for i in range(data_run2_df.shape[0])]\n",
    "data_run2_df[\"run_num\"] = [2 for i in range(data_run2_df.shape[0])]\n",
    "\n",
    "f_data_run3 = uproot.open(wc_file_location + \"checkout_data_bnb_run3_all.root\")[\"wcpselection\"]\n",
    "f_data_run3_bdt = f_data_run3[\"T_BDTvars\"].pandas.df(bdt_vars, flatten=False)\n",
    "f_data_run3_eval = f_data_run3[\"T_eval\"].pandas.df(eval_data_variables + [\"match_isFC\"], flatten=False)\n",
    "f_data_run3_pfeval = f_data_run3[\"T_PFeval\"].pandas.df(pf_eval_data_variables, flatten=False)\n",
    "f_data_run3_kine = f_data_run3[\"T_KINEvars\"].pandas.df(kine_scalar_vars + kine_vector_vars + [\"kine_reco_Enu\"], flatten=False)\n",
    "data_run3_df = pd.concat([f_data_run3_bdt, f_data_run3_eval, f_data_run3_pfeval, f_data_run3_kine], axis=1, sort=False)\n",
    "del f_data_run3\n",
    "del f_data_run3_bdt\n",
    "del f_data_run3_eval\n",
    "del f_data_run3_pfeval\n",
    "del f_data_run3_kine\n",
    "data_run3_df[\"isEXT\"] = [0 for i in range(data_run3_df.shape[0])]\n",
    "data_run3_df[\"isDirt\"] = [0 for i in range(data_run3_df.shape[0])]\n",
    "data_run3_df[\"WC_file\"] = [\"data_run3\" for i in range(data_run3_df.shape[0])]\n",
    "data_run3_df[\"category\"] = [\"data\" for i in range(data_run3_df.shape[0])]\n",
    "data_run3_df[\"run_num\"] = [3 for i in range(data_run3_df.shape[0])]\n",
    "\n",
    "\n",
    "data_all_df = pd.concat([data_run1_df, data_run2_df, data_run3_df], sort=False)\n",
    "\n",
    "del data_run1_df\n",
    "del data_run2_df\n",
    "del data_run3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5c2de93-0021-4be0-ad5d-30f248de080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining prediction files\n",
    "\n",
    "all_df = pd.concat([overlay_df, ext_df, dirt_df, nc_delta_df, intrinsic_nue_df, nc_pi0_df], sort=False)\n",
    "\n",
    "del overlay_df\n",
    "del ext_df\n",
    "del dirt_df\n",
    "del nc_delta_df\n",
    "del intrinsic_nue_df\n",
    "del nc_pi0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22f2fd26-d913-4663-9fa4-590788f3b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 8119423/8119423 [00:37<00:00, 219287.09it/s]\n"
     ]
    }
   ],
   "source": [
    "normalizing_POT_run1 = 1.423e20\n",
    "normalizing_POT_run2 = 2.541e20\n",
    "normalizing_POT_run3 = 2.405e20\n",
    "\n",
    "weight_cv = all_df[\"weight_cv\"].to_numpy()\n",
    "weight_spline = all_df[\"weight_spline\"].to_numpy()\n",
    "is_ext = all_df[\"isEXT\"].to_numpy()\n",
    "is_dirt = all_df[\"isDirt\"].to_numpy()\n",
    "is_nc_delta = all_df[\"truth_NCDelta\"].to_numpy() # should give 0 for data (truth_NCDelta==NaN)\n",
    "is_CC = all_df[\"truth_isCC\"].to_numpy() # should give 0 for data (truth_isCC==NaN)\n",
    "num_pi0 = all_df[\"truth_NprimPio\"].to_numpy() # should give 0 for data (truth_NprimPio==NaN)\n",
    "truth_nuPdgs = all_df[\"truth_nuPdg\"].to_numpy()\n",
    "\n",
    "\n",
    "run_nums = all_df[\"run_num\"].to_numpy()\n",
    "WC_file_str = all_df[\"WC_file\"].to_numpy()\n",
    "net_weights = []\n",
    "for i in tqdm(range(len(weight_cv))):\n",
    "    weight_temp = weight_cv[i] * weight_spline[i]\n",
    "    if weight_temp <= 0. or weight_temp > 30. or np.isnan(weight_temp): # something went wrong with the saved weights\n",
    "        weight_temp = 1.\n",
    "    if run_nums[i] == 1:\n",
    "        if is_ext[i]:\n",
    "            net_weights.append(normalizing_POT_run1 / ext_run1_POT)\n",
    "        elif is_dirt[i]:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run1 / dirt_run1_POT)\n",
    "        elif is_nc_delta[i]:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run1 / nc_delta_run1_file_POT)\n",
    "        elif not is_CC[i] and num_pi0[i] > 0:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run1 / nc_pi0_run1_file_POT)\n",
    "        elif is_CC[i] and abs(truth_nuPdgs[i]) == 12:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run1 / intrinsic_nue_run1_file_POT)\n",
    "        else:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run1 / nu_overlay_run1_POT)\n",
    "    elif run_nums[i] == 2:\n",
    "        if is_ext[i]:\n",
    "            net_weights.append(normalizing_POT_run2 / ext_run2_POT)\n",
    "        elif is_dirt[i]:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run2 / dirt_run2_POT)\n",
    "        elif is_nc_delta[i]:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run2 / nc_delta_run2_file_POT)\n",
    "        elif not is_CC[i] and num_pi0[i] > 0:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run2 / nc_pi0_run2_file_POT)\n",
    "        elif is_CC[i] and abs(truth_nuPdgs[i]) == 12:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run2 / intrinsic_nue_run2_file_POT)\n",
    "        else:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run2 / nu_overlay_run2_POT)\n",
    "    elif run_nums[i] == 3:\n",
    "        if is_ext[i]:\n",
    "            net_weights.append(normalizing_POT_run3 / ext_run3_POT)\n",
    "        elif is_dirt[i]:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run3 / dirt_run3_POT)\n",
    "        elif is_nc_delta[i]:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run3 / nc_delta_run3_file_POT)\n",
    "        elif not is_CC[i] and num_pi0[i] > 0:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run3 / nc_pi0_run3_file_POT)\n",
    "        elif is_CC[i] and abs(truth_nuPdgs[i]) == 12:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run3 / intrinsic_nue_run3_file_POT)\n",
    "        else:\n",
    "            net_weights.append(weight_temp * normalizing_POT_run3 / nu_overlay_run3_POT)\n",
    "\n",
    "all_df[\"net_weight\"] = net_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c73c768-84a3-41b3-adf4-485d54046281",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_charge_scale = 0.95\n",
    "\n",
    "uncorrected_reco_showerKE = all_df[\"reco_showerKE\"].to_numpy()\n",
    "all_df[\"reco_showerKE\"] = uncorrected_reco_showerKE * 1000.\n",
    "\n",
    "uncorrected_reco_showerKE = data_all_df[\"reco_showerKE\"].to_numpy()\n",
    "data_all_df[\"reco_showerKE\"] = em_charge_scale * uncorrected_reco_showerKE * 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a3a26b3-5266-4ca6-86fe-4b9c266f19fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 8119423/8119423 [00:42<00:00, 189293.64it/s]\n",
      "100%|█████████████████████████████| 2421328/2421328 [00:06<00:00, 349008.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# adding WC reco proton num\n",
    "\n",
    "proton_nums = []\n",
    "track_nums = []\n",
    "energy_lists = all_df[\"kine_energy_particle\"].to_numpy()\n",
    "pdg_lists = all_df[\"kine_particle_type\"].to_numpy()\n",
    "for i in tqdm(range(all_df.shape[0])):\n",
    "    proton_num = 0\n",
    "    track_num = 0\n",
    "    energy_list = energy_lists[i]\n",
    "    pdg_list = pdg_lists[i]\n",
    "    for i in range(len(energy_list)):\n",
    "        if abs(pdg_list[i]) == 2212 and energy_list[i] > 35.:\n",
    "            proton_num += 1\n",
    "        if abs(pdg_list[i]) == 13 or abs(pdg_list[i]) == 211 and energy_list[i] > 10.: # see N_tracks at https://github.com/BNLIF/wcp-uboone-bdt/blob/main/inc/WCPleeANA/cuts.h\n",
    "            track_num += 1\n",
    "    proton_nums.append(proton_num)\n",
    "    track_nums.append(track_num)\n",
    "all_df[\"WC_reco_num_protons\"] = proton_nums\n",
    "all_df[\"WC_reco_num_other_tracks\"] = track_nums\n",
    "\n",
    "proton_nums = []\n",
    "track_nums = []\n",
    "energy_lists = data_all_df[\"kine_energy_particle\"].to_numpy()\n",
    "pdg_lists = data_all_df[\"kine_particle_type\"].to_numpy()\n",
    "for i in tqdm(range(data_all_df.shape[0])):\n",
    "    proton_num = 0\n",
    "    track_num = 0\n",
    "    energy_list = energy_lists[i]\n",
    "    pdg_list = pdg_lists[i]\n",
    "    for i in range(len(energy_list)):\n",
    "        if abs(pdg_list[i]) == 2212 and energy_list[i] > 35.:\n",
    "            proton_num += 1\n",
    "        if abs(pdg_list[i]) == 13 or abs(pdg_list[i]) == 211 and energy_list[i] > 10.: # see N_tracks at https://github.com/BNLIF/wcp-uboone-bdt/blob/main/inc/WCPleeANA/cuts.h\n",
    "            track_num += 1\n",
    "    proton_nums.append(proton_num)\n",
    "    track_nums.append(track_num)\n",
    "data_all_df[\"WC_reco_num_protons\"] = proton_nums\n",
    "data_all_df[\"WC_reco_num_other_tracks\"] = track_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98471763-2c63-4774-8ff9-8ee2a28b477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]/home/hagaman/anaconda3/envs/three_point_seven_env/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|███████████████████████████████████████████| 10/10 [00:05<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# adding WC truth category information\n",
    "\n",
    "categories = [\"NC Delta Radiative\", \"NC 1 Pi0\", \"numuCC 1 Pi0\", \"nueCC\", \"numuCC other\", \"NC other\", \"outFV\", \"badmatch/cosmic\", \"dirt\", \"ext\"]\n",
    "\n",
    "queries = [\n",
    "    \"not (isDirt==1) and not (isEXT==1) and match_completeness_energy/truth_energyInside>=0.1 and truth_vtxInside==1 and truth_isCC==0 and truth_NCDelta==1\",\n",
    "    \"not (isDirt==1) and not (isEXT==1) and match_completeness_energy/truth_energyInside>=0.1 and truth_vtxInside==1 and truth_isCC==0 and truth_NprimPio==1 and not (truth_NCDelta==1)\",\n",
    "    \"not (isDirt==1) and not (isEXT==1) and match_completeness_energy/truth_energyInside>=0.1 and truth_vtxInside==1 and truth_isCC==1 and abs(truth_nuPdg)==14 and truth_NprimPio==1\",\n",
    "    \"not (isDirt==1) and not (isEXT==1) and match_completeness_energy/truth_energyInside>=0.1 and truth_vtxInside==1 and truth_isCC==1 and abs(truth_nuPdg)==12\",\n",
    "    \"not (isDirt==1) and not (isEXT==1) and match_completeness_energy/truth_energyInside>=0.1 and truth_vtxInside==1 and truth_isCC==1 and abs(truth_nuPdg)==14 and truth_NprimPio!=1\",\n",
    "    \"not (isDirt==1) and not (isEXT==1) and match_completeness_energy/truth_energyInside>=0.1 and truth_vtxInside==1 and truth_isCC==0 and truth_NprimPio!=1 and not (truth_NCDelta==1)\",\n",
    "    \"not (isDirt==1) and not (isEXT==1) and match_completeness_energy/truth_energyInside>=0.1 and not (truth_vtxInside==1)\",\n",
    "    \"not (isDirt==1) and not (isEXT==1) and not (match_completeness_energy/truth_energyInside>=0.1)\",\n",
    "    \"isDirt==1\",\n",
    "    \"isEXT==1\",\n",
    "]\n",
    "\n",
    "dfs_with_categories = []\n",
    "for i in tqdm(range(len(categories))):\n",
    "    category = categories[i]\n",
    "    query = queries[i]\n",
    "    cat_df = all_df.query(query)\n",
    "    cat_df[\"category\"] = category\n",
    "    dfs_with_categories.append(cat_df)\n",
    "    \n",
    "del all_df\n",
    "all_df = pd.concat(dfs_with_categories, sort=False)\n",
    "\n",
    "del cat_df\n",
    "del dfs_with_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd0653ef-20a6-41ff-b149-d079ce5bad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[\"data_or_pred\"] = [\"pred\" for i in range(all_df.shape[0])]\n",
    "data_all_df[\"data_or_pred\"] = [\"data\" for i in range(data_all_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5533e70-ed22-4de6-996e-18d69c4818ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting them in order so that we don't remove the only generic selected event when we remove duplicates\n",
    "all_df.sort_values(by=[\"kine_reco_Enu\"], inplace=True, ascending=False)\n",
    "data_all_df.sort_values(by=[\"kine_reco_Enu\"], inplace=True, ascending=False)\n",
    "\n",
    "all_df.reset_index(inplace=True)\n",
    "data_all_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4133a12f-2d29-4f6c-9f40-e9bf1bb87845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates still included:\n",
      "8119423\n",
      "2421328\n"
     ]
    }
   ],
   "source": [
    "print(\"duplicates still included:\")\n",
    "print(all_df.shape[0])\n",
    "print(data_all_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97b6fde5-afd5-4074-b75d-3d4a4abd2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate RSE nums, would be an issue when merging\n",
    "\n",
    "data_duplicate_row_list = data_all_df[[\"run\", \"subrun\", \"event\"]].duplicated().to_numpy()\n",
    "pred_duplicate_row_list = all_df[[\"run\", \"subrun\", \"event\"]].duplicated().to_numpy()\n",
    "\n",
    "data_duplicate_indices = list(np.nonzero(data_duplicate_row_list)[0])\n",
    "pred_duplicate_indices = list(np.nonzero(pred_duplicate_row_list)[0])\n",
    "data_duplicate_row_list = data_all_df[[\"run\", \"subrun\", \"event\"]].duplicated().to_numpy()\n",
    "pred_duplicate_row_list = all_df[[\"run\", \"subrun\", \"event\"]].duplicated().to_numpy()\n",
    "\n",
    "data_duplicate_indices = list(np.nonzero(data_duplicate_row_list)[0])\n",
    "pred_duplicate_indices = list(np.nonzero(pred_duplicate_row_list)[0])\n",
    "\n",
    "data_all_df.drop(data_duplicate_indices, inplace=True)\n",
    "all_df.drop(pred_duplicate_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89269532-c965-4f57-ac65-c809d84460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# throwing away excess information, combining data and MC files, randomizing order\n",
    "WC_all_df = pd.concat([all_df[wc_vars], data_all_df[wc_data_vars]], sort=False).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0185866-bcfd-41ed-acb0-2d3d0e4e73cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates removed:\n",
      "8087438\n",
      "2421328\n",
      "\n",
      "combined:\n",
      "10508766\n"
     ]
    }
   ],
   "source": [
    "print(\"duplicates removed:\")\n",
    "print(all_df.shape[0])\n",
    "print(data_all_df.shape[0])\n",
    "\n",
    "print(\"\\ncombined:\")\n",
    "print(WC_all_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40f889dd-13ef-4bbd-b090-4b56ba97c0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(WC_all_df[[\"run\", \"subrun\", \"event\"]].duplicated().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7343a65e-8061-47f4-bdf7-de6f2171ebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "merged_glee_WC_comparison_df = WC_all_df.merge(glee_all_df, how=\"outer\", on=[\"data_or_pred\", \"run\", \"subrun\", \"event\"])\n",
    "merged_glee_WC_comparison_df.to_pickle(\"merged_glee_WC_comparison_df_full_v1.pkl\")\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73cfb96d-7aa9-4514-be91-2579cdd49595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['data_or_pred', 'run', 'subrun', 'event', 'category', 'WC_file',\n",
       "       'match_isFC', 'kine_reco_Enu', 'reco_showerKE', 'nc_delta_score',\n",
       "       'WC_reco_num_protons', 'WC_reco_num_other_tracks', 'reco_nuvtxX',\n",
       "       'reco_nuvtxY', 'reco_nuvtxZ', 'truth_vtxX', 'truth_vtxY', 'truth_vtxZ',\n",
       "       'net_weight', 'entry', 'reco_shower_energy_plane0',\n",
       "       'reco_shower_energy_plane1', 'reco_shower_energy_plane2',\n",
       "       'reco_shower_energy_max', 'reco_vertex_x', 'reco_vertex_y',\n",
       "       'reco_vertex_z', 'simple_pot_weight', 'glee_file', 'glee_selection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_glee_WC_comparison_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06c5144e-76cc-4960-988b-ab5fb840474a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_or_pred</th>\n",
       "      <th>run</th>\n",
       "      <th>subrun</th>\n",
       "      <th>event</th>\n",
       "      <th>category</th>\n",
       "      <th>WC_file</th>\n",
       "      <th>match_isFC</th>\n",
       "      <th>kine_reco_Enu</th>\n",
       "      <th>reco_showerKE</th>\n",
       "      <th>nc_delta_score</th>\n",
       "      <th>...</th>\n",
       "      <th>reco_shower_energy_plane0</th>\n",
       "      <th>reco_shower_energy_plane1</th>\n",
       "      <th>reco_shower_energy_plane2</th>\n",
       "      <th>reco_shower_energy_max</th>\n",
       "      <th>reco_vertex_x</th>\n",
       "      <th>reco_vertex_y</th>\n",
       "      <th>reco_vertex_z</th>\n",
       "      <th>simple_pot_weight</th>\n",
       "      <th>glee_file</th>\n",
       "      <th>glee_selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pred</td>\n",
       "      <td>18032</td>\n",
       "      <td>62</td>\n",
       "      <td>3123</td>\n",
       "      <td>ext</td>\n",
       "      <td>ext_run3</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1000.000000</td>\n",
       "      <td>-2.275953</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pred</td>\n",
       "      <td>17560</td>\n",
       "      <td>93</td>\n",
       "      <td>4689</td>\n",
       "      <td>numuCC other</td>\n",
       "      <td>nu_overlay_run3</td>\n",
       "      <td>False</td>\n",
       "      <td>357.782501</td>\n",
       "      <td>114.468925</td>\n",
       "      <td>-5.453149</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pred</td>\n",
       "      <td>9545</td>\n",
       "      <td>231</td>\n",
       "      <td>11576</td>\n",
       "      <td>NC 1 Pi0</td>\n",
       "      <td>NC_Pi0_run2</td>\n",
       "      <td>True</td>\n",
       "      <td>326.510406</td>\n",
       "      <td>108.675423</td>\n",
       "      <td>-1.706928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pred</td>\n",
       "      <td>12364</td>\n",
       "      <td>37</td>\n",
       "      <td>1861</td>\n",
       "      <td>ext</td>\n",
       "      <td>ext_run2</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1000.000000</td>\n",
       "      <td>-2.275953</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pred</td>\n",
       "      <td>7492</td>\n",
       "      <td>8</td>\n",
       "      <td>417</td>\n",
       "      <td>ext</td>\n",
       "      <td>ext_run1</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1000.000000</td>\n",
       "      <td>-2.275953</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510531</th>\n",
       "      <td>data</td>\n",
       "      <td>5519</td>\n",
       "      <td>99</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.678651</td>\n",
       "      <td>142.248800</td>\n",
       "      <td>164.402147</td>\n",
       "      <td>164.402147</td>\n",
       "      <td>227.585846</td>\n",
       "      <td>69.191933</td>\n",
       "      <td>504.145142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data</td>\n",
       "      <td>1g0p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510532</th>\n",
       "      <td>data</td>\n",
       "      <td>8750</td>\n",
       "      <td>344</td>\n",
       "      <td>17205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>89.911065</td>\n",
       "      <td>206.786793</td>\n",
       "      <td>266.836514</td>\n",
       "      <td>266.836514</td>\n",
       "      <td>59.691727</td>\n",
       "      <td>79.927483</td>\n",
       "      <td>294.536957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data</td>\n",
       "      <td>1g0p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510533</th>\n",
       "      <td>data</td>\n",
       "      <td>5762</td>\n",
       "      <td>114</td>\n",
       "      <td>5732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>143.989547</td>\n",
       "      <td>186.020242</td>\n",
       "      <td>186.856392</td>\n",
       "      <td>186.856392</td>\n",
       "      <td>113.383087</td>\n",
       "      <td>60.917236</td>\n",
       "      <td>541.001648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510534</th>\n",
       "      <td>data</td>\n",
       "      <td>5634</td>\n",
       "      <td>22</td>\n",
       "      <td>1149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>136.021075</td>\n",
       "      <td>125.121449</td>\n",
       "      <td>146.504544</td>\n",
       "      <td>146.504544</td>\n",
       "      <td>153.665298</td>\n",
       "      <td>-8.323478</td>\n",
       "      <td>1006.099976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510535</th>\n",
       "      <td>data</td>\n",
       "      <td>14736</td>\n",
       "      <td>179</td>\n",
       "      <td>8961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>370.253497</td>\n",
       "      <td>240.394299</td>\n",
       "      <td>480.185831</td>\n",
       "      <td>480.185831</td>\n",
       "      <td>142.115280</td>\n",
       "      <td>-77.809120</td>\n",
       "      <td>923.357666</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data</td>\n",
       "      <td>1g1p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10510536 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         data_or_pred    run  subrun  event      category          WC_file  \\\n",
       "0                pred  18032      62   3123           ext         ext_run3   \n",
       "1                pred  17560      93   4689  numuCC other  nu_overlay_run3   \n",
       "2                pred   9545     231  11576      NC 1 Pi0      NC_Pi0_run2   \n",
       "3                pred  12364      37   1861           ext         ext_run2   \n",
       "4                pred   7492       8    417           ext         ext_run1   \n",
       "...               ...    ...     ...    ...           ...              ...   \n",
       "10510531         data   5519      99   5000           NaN              NaN   \n",
       "10510532         data   8750     344  17205           NaN              NaN   \n",
       "10510533         data   5762     114   5732           NaN              NaN   \n",
       "10510534         data   5634      22   1149           NaN              NaN   \n",
       "10510535         data  14736     179   8961           NaN              NaN   \n",
       "\n",
       "         match_isFC  kine_reco_Enu  reco_showerKE  nc_delta_score  ...  \\\n",
       "0             False      -1.000000   -1000.000000       -2.275953  ...   \n",
       "1             False     357.782501     114.468925       -5.453149  ...   \n",
       "2              True     326.510406     108.675423       -1.706928  ...   \n",
       "3             False      -1.000000   -1000.000000       -2.275953  ...   \n",
       "4              True      -1.000000   -1000.000000       -2.275953  ...   \n",
       "...             ...            ...            ...             ...  ...   \n",
       "10510531        NaN            NaN            NaN             NaN  ...   \n",
       "10510532        NaN            NaN            NaN             NaN  ...   \n",
       "10510533        NaN            NaN            NaN             NaN  ...   \n",
       "10510534        NaN            NaN            NaN             NaN  ...   \n",
       "10510535        NaN            NaN            NaN             NaN  ...   \n",
       "\n",
       "          reco_shower_energy_plane0  reco_shower_energy_plane1  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "...                             ...                        ...   \n",
       "10510531                 135.678651                 142.248800   \n",
       "10510532                  89.911065                 206.786793   \n",
       "10510533                 143.989547                 186.020242   \n",
       "10510534                 136.021075                 125.121449   \n",
       "10510535                 370.253497                 240.394299   \n",
       "\n",
       "          reco_shower_energy_plane2  reco_shower_energy_max  reco_vertex_x  \\\n",
       "0                               NaN                     NaN            NaN   \n",
       "1                               NaN                     NaN            NaN   \n",
       "2                               NaN                     NaN            NaN   \n",
       "3                               NaN                     NaN            NaN   \n",
       "4                               NaN                     NaN            NaN   \n",
       "...                             ...                     ...            ...   \n",
       "10510531                 164.402147              164.402147     227.585846   \n",
       "10510532                 266.836514              266.836514      59.691727   \n",
       "10510533                 186.856392              186.856392     113.383087   \n",
       "10510534                 146.504544              146.504544     153.665298   \n",
       "10510535                 480.185831              480.185831     142.115280   \n",
       "\n",
       "          reco_vertex_y  reco_vertex_z  simple_pot_weight  glee_file  \\\n",
       "0                   NaN            NaN                NaN        NaN   \n",
       "1                   NaN            NaN                NaN        NaN   \n",
       "2                   NaN            NaN                NaN        NaN   \n",
       "3                   NaN            NaN                NaN        NaN   \n",
       "4                   NaN            NaN                NaN        NaN   \n",
       "...                 ...            ...                ...        ...   \n",
       "10510531      69.191933     504.145142                1.0       data   \n",
       "10510532      79.927483     294.536957                1.0       data   \n",
       "10510533      60.917236     541.001648                1.0       data   \n",
       "10510534      -8.323478    1006.099976                1.0       data   \n",
       "10510535     -77.809120     923.357666                1.0       data   \n",
       "\n",
       "          glee_selection  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "10510531            1g0p  \n",
       "10510532            1g0p  \n",
       "10510533            1g1p  \n",
       "10510534            1g1p  \n",
       "10510535            1g1p  \n",
       "\n",
       "[10510536 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_glee_WC_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a19df476-8678-4ebb-ae76-92d0645d0fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# evaluate overlap fractions\\n# (could loosen the WC truth orthogonality cuts to up some of these fractions)\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NCDeltaRadOverlaySM\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NCDeltaRadOverlaySM\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p NCDeltaRadOverlaySM events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NCPi0Coh\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NCPi0Coh\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p NCPi0Coh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NCPi0NotCoh\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NCPi0NotCoh\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p NCPi0NotCoh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'CC1Pi0\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'CC1Pi0\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p CC1Pi0 events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NueOverlays\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'NueOverlays\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p NueOverlays events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'OTPCExtra\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'OTPCExtra\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p OTPCExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'BNBOtherExtra\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'BNBOtherExtra\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p BNBOtherExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'Dirt\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'Dirt\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p Dirt events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'BNBext\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'BNBext\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p BNBext events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'data\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g0p\\' and glee_file==\\'data\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g0p data events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\nprint(\"\\n\\n\")\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NCDeltaRadOverlaySM\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NCDeltaRadOverlaySM\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p NCDeltaRadOverlaySM events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NCPi0Coh\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NCPi0Coh\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p NCPi0Coh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NCPi0NotCoh\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NCPi0NotCoh\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p NCPi0NotCoh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'CC1Pi0\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'CC1Pi0\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p CC1Pi0 events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NueOverlays\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'NueOverlays\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p NueOverlays events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'OTPCExtra\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'OTPCExtra\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p OTPCExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'BNBOtherExtra\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'BNBOtherExtra\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p BNBOtherExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'Dirt\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'Dirt\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p Dirt events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'BNBext\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'BNBext\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p BNBext events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n\\ntotal_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'data\\'\")[\"simple_pot_weight\"].to_numpy())\\ntotal_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\\n    \"glee_selection==\\'1g1p\\' and glee_file==\\'data\\' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\\nprint(\"fraction of glee 1g1p data events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# evaluate overlap fractions\n",
    "# (could loosen the WC truth orthogonality cuts to up some of these fractions)\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NCDeltaRadOverlaySM'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NCDeltaRadOverlaySM' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p NCDeltaRadOverlaySM events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NCPi0Coh'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NCPi0Coh' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p NCPi0Coh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NCPi0NotCoh'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NCPi0NotCoh' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p NCPi0NotCoh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='CC1Pi0'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='CC1Pi0' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p CC1Pi0 events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NueOverlays'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='NueOverlays' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p NueOverlays events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='OTPCExtra'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='OTPCExtra' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p OTPCExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='BNBOtherExtra'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='BNBOtherExtra' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p BNBOtherExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='Dirt'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='Dirt' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p Dirt events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='BNBext'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='BNBext' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p BNBext events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='data'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g0p' and glee_file=='data' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g0p data events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NCDeltaRadOverlaySM'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NCDeltaRadOverlaySM' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p NCDeltaRadOverlaySM events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NCPi0Coh'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NCPi0Coh' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p NCPi0Coh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NCPi0NotCoh'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NCPi0NotCoh' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p NCPi0NotCoh events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='CC1Pi0'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='CC1Pi0' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p CC1Pi0 events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NueOverlays'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='NueOverlays' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p NueOverlays events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='OTPCExtra'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='OTPCExtra' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p OTPCExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='BNBOtherExtra'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='BNBOtherExtra' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p BNBOtherExtra events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='Dirt'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='Dirt' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p Dirt events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='BNBext'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='BNBext' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p BNBext events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\n",
    "total_pred_glee = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='data'\")[\"simple_pot_weight\"].to_numpy())\n",
    "total_pred_glee_in_a_wc_file = np.sum(merged_glee_WC_comparison_df.query(\n",
    "    \"glee_selection=='1g1p' and glee_file=='data' and WC_file==WC_file\")[\"simple_pot_weight\"].to_numpy())\n",
    "print(\"fraction of glee 1g1p data events in WC files:\", np.round(total_pred_glee_in_a_wc_file, 4), \"/\", np.round(total_pred_glee, 4), \"=\", np.round(total_pred_glee_in_a_wc_file / total_pred_glee, 4))\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037debb-e68c-4caa-a5e9-20a4a245543a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
